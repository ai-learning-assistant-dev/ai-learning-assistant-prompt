# v1.0
一切都从这个东西作为原版提示词开始。这个版本通过v3做出来的东西基本上能够抓住重点，但是容易对笔记的内容有所缺漏，并且生成的文本在格式上较为杂乱。

因为上传的这个时候这个提示词已经抵达1.2版本，所以不在这里谈论做提示词的测试背景。
# v1.1
这个版本在内容的完整度上有所优化，并且也较为精简。但是在论证上常常一笔带过，没看过视频的人很难懂，从1.0版本起就没有很好的改善。

因为上传的这个时候这个提示词已经抵达1.2版本，所以不在这里谈论做提示词的测试背景。
# v1.2
25token的上下文状况下，对于2-3份对老未的视频所做的、有详有略的笔记（这也是它最主要的测试环境），它可以用7-8k的token完成一篇简报（较为简略，没看过视频会觉得有点云山雾罩或者有点无聊，看过视频的隐隐会觉得似乎漏了点什么东西）。这个版本基本可以投入正常使用，总体上来说体量精简，而如果投喂老未的视频文稿，他能够弄出来内容上基本齐全的东西。可以处理多份笔记（虽然能用来实验的、大于2份的、同一节点的笔记在目前，也就是2025年6月12日，数量上比较捉襟见肘，但总的来说效果是较有保证的），但多份笔记容易出现更大的内容损失。

论证的一笔带过情况相较于以往版本有较好的改善，但是改善也比较有限。比如，我自己看我没看过的主义主义文稿整合出来的笔记，因为最终文本里给出的例证和解释有限，有吃压缩饼干的感觉。虽然说能够通过后续继续提问“让压缩饼干泡水软化”，但也需要注意这一点。

这个版本最终生成的文本用比较通用的markdown和mermaid语法，虽然涉及中文，但基本能保证不会出现问题。

让提示词工程的、deepseek的R1执行可以基本客观评价效果的特定任务，得到的朴素经验包括：适合论证分析、任务必须大量拆分并且提供验证环节（抓手越多它越能符合论）、如果想要看得懂他在说什么就必须严格在提示词把字数下限提高、它所撰写的md语法文本容易因为中文使用语境而出现错误。
# v1.3
在1.2版本上作出了改进，主要测试环境为豆包1.6thinking，这玩意儿比deepseekR1脑子转多了，并且价格上也比ds省。希望对比各个chat模型的可以看一下这个链接：[https://github.com/malody2014/llm_benchmark](https://github.com/malody2014/llm_benchmark)

一方面，这个提示词在相同的任务压力下调用的token更少了；另一方面，保留了之前的好特性。它在豆包1.6thinking上可以完成视频校对粗稿、视频校对细稿、笔记的整合，基本不再出现dsR1那样的过度概括情况。这非常好。

在豆包1.6thinking，0.7temperature，Tavily作为网络搜索引擎的条件下，这篇提示词实现：

1. 上传1字头的笔记（1-1-1-3共计2篇），它完成一篇不错的（可以抛弃视频和笔记，直接阅读整合后的文本，而能获得准确知识的）整合文本，总共10.6k token完成这一任务。
2. 上传2字头的一篇视频文本校对粗稿（2-1-4-3），它完成一篇不错的整合文本，总共22k token完成这一任务。
3. 上传3字头的笔记（3-1共计2篇），它完成一篇不错的整合文本，总共10.4k token完成这一任务。
4. 上传3字头的笔记（3-3-4-1共计2篇），它完成一篇不错的整合文本，总共20k token完成这一任务。

对于原来的dsR1也用相同的提示词和条件加以测试，实现：

1. 上传3字头的笔记（3-3-4-1共计2篇），它完成一篇可看的简报（较为简略，没看过视频会觉得有点云山雾罩或者有点无聊，看过视频的隐隐会觉得似乎漏了点什么东西，是ds的老毛病），共计8.4k token完成这一任务。
2. 其他差不多还是老样子，就是在7-8k token上下可以完成简报。

所以，这个提示词对于ds和豆包，可以分别用于获取简报和不错的整合文本。整个提示词的token为3.6k token。提示词本体在分隔符下方放出。
# v1.4
这个版本让提示词更加精炼了，并且做了对多项笔记整合情境的优化，它现在最终可以将多项笔记博采众长，生成一个可读性很高的最终文本。

仅在豆包1.6thinking完成测试。不保证deepseekr1甚至v3能够完成任务。但对于已经抵达这个简洁程度的提示词而言，如果ds最终完成任务的情况仍然不尽如人意，那可能我作为作者也要挠头了。如果真的有较低性能模型的需求，那我再做低性能模型的优化版本吧。
